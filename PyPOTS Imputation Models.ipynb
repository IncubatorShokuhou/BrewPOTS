{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“‘ Tutorials for PyPOTS Imputation Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“€ Preparing the **PhysioNet-2012** dataset for this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 09:33:46 [INFO]: Loading the dataset physionet_2012 with TSDB (https://github.com/WenjieDu/Time_Series_Database)...\n",
      "2023-04-25 09:33:46 [INFO]: Starting preprocessing physionet_2012...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset physionet_2012 has already been downloaded. Processing directly...\n",
      "Dataset physionet_2012 has already been cached. Loading from cache directly...\n",
      "Loaded successfully!\n",
      "dict_keys(['n_classes', 'n_steps', 'n_features', 'train_X', 'train_y', 'val_X', 'val_y', 'test_X', 'test_y', 'scaler', 'test_X_intact', 'test_X_indicating_mask', 'val_X_intact', 'val_X_indicating_mask'])\n"
     ]
    }
   ],
   "source": [
    "from pypots.data.generating import gene_physionet2012\n",
    "\n",
    "# Load the PhysioNet-2012 dataset\n",
    "physionet2012_dataset = gene_physionet2012(artificially_missing=True)\n",
    "\n",
    "# Take a look at the generated PhysioNet-2012 dataset, you'll find that everything has been prepared for you, \n",
    "# data splitting, normalization, additional artificially-missing values for evaluation, etc.\n",
    "print(physionet2012_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the datasets for training, validating, and testing.\n",
    "\n",
    "dataset_for_training = {\n",
    "    \"X\": physionet2012_dataset['train_X'],\n",
    "}\n",
    "\n",
    "dataset_for_validating = {\n",
    "    \"X\": physionet2012_dataset['val_X'],\n",
    "    \"X_intact\": physionet2012_dataset['val_X_intact'],\n",
    "    \"indicating_mask\": physionet2012_dataset['val_X_indicating_mask'],\n",
    "}\n",
    "\n",
    "dataset_for_testing = {\n",
    "    \"X\": physionet2012_dataset['test_X'],\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ An exmaple of **SAITS** for imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 09:34:15 [INFO]: No given device, using default device: cpu\n",
      "2023-04-25 09:34:15 [INFO]: saving_path is set as tutorial_results/imputation/saits, the trained model will be saved to tutorial_results/imputation/saits/20230425_T093415, the tensorboard file will be saved to tutorial_results/imputation/saits/20230425_T093415/tensorboard\n",
      "2023-04-25 09:34:15 [INFO]: Model initialized successfully with the number of trainable parameters: 1378358\n"
     ]
    }
   ],
   "source": [
    "from pypots.imputation import SAITS\n",
    "\n",
    "# initialize the model\n",
    "saits = SAITS(\n",
    "    n_steps=physionet2012_dataset['n_steps'], \n",
    "    n_features=physionet2012_dataset['n_features'], \n",
    "    n_layers=2, \n",
    "    d_model=256, \n",
    "    d_inner=128, \n",
    "    n_head=4, \n",
    "    d_k=64, \n",
    "    d_v=64, \n",
    "    dropout=0.1, \n",
    "    epochs=10, # here we set epochs=10 for a quick demo, you can set it to 100 or more for better performance\n",
    "    patience=3, # here we set patience=5 to early stop the training if the evaluting loss doesn't decrease for 5 epoches. You can leave it to defualt as None to disable early stopping.\n",
    "    learning_rate=1e-3,\n",
    "    # device='cpu', # just leave it to default, PyPOTS will automatically assign the best device for you. \n",
    "                    # Set it to 'cpu' if you don't have CUDA devices. You can also set it to 'cuda:0' or 'cuda:1' if you have multiple CUDA devices.\n",
    "    saving_path=\"tutorial_results/imputation/saits\", # set the path for saving tensorboard files\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 09:34:48 [INFO]: epoch 0: training loss 0.7129, validating loss 0.3242\n",
      "2023-04-25 09:35:20 [INFO]: epoch 1: training loss 0.5033, validating loss 0.2984\n",
      "2023-04-25 09:35:53 [INFO]: epoch 2: training loss 0.4429, validating loss 0.2737\n",
      "2023-04-25 09:36:26 [INFO]: epoch 3: training loss 0.4069, validating loss 0.2594\n",
      "2023-04-25 09:36:59 [INFO]: epoch 4: training loss 0.3779, validating loss 0.2512\n",
      "2023-04-25 09:37:30 [INFO]: epoch 5: training loss 0.3593, validating loss 0.2440\n",
      "2023-04-25 09:38:02 [INFO]: epoch 6: training loss 0.3446, validating loss 0.2384\n",
      "2023-04-25 09:38:34 [INFO]: epoch 7: training loss 0.3338, validating loss 0.2387\n",
      "2023-04-25 09:39:06 [INFO]: epoch 8: training loss 0.3262, validating loss 0.2329\n",
      "2023-04-25 09:39:38 [INFO]: epoch 9: training loss 0.3218, validating loss 0.2309\n",
      "2023-04-25 09:39:38 [INFO]: Finished training.\n",
      "2023-04-25 09:39:38 [INFO]: Saved successfully to tutorial_results/imputation/saits/20230425_T093415/SAITS.pypots.\n"
     ]
    }
   ],
   "source": [
    "# train the model on the training set, and validate it on the validating set to select the best model for testing in the next step\n",
    "saits.fit(train_set=dataset_for_training, val_set=dataset_for_validating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the testing stage, impute the originally-missing values and artificially-missing values in the test set\n",
    "saits_imputation = saits.impute(dataset_for_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing mean absolute error: 0.2302\n"
     ]
    }
   ],
   "source": [
    "from pypots.utils.metrics import cal_mae\n",
    "\n",
    "# calculate mean absolute error on the ground truth (artificially-missing values)\n",
    "testing_mae = cal_mae(saits_imputation, physionet2012_dataset['test_X_intact'], physionet2012_dataset['test_X_indicating_mask'])\n",
    "print(\"Testing mean absolute error: %.4f\" % testing_mae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ An exmaple of **Transformer** for imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 09:39:42 [INFO]: No given device, using default device: cpu\n",
      "2023-04-25 09:39:42 [INFO]: saving_path is set as tutorial_results/imputation/transformer, the trained model will be saved to tutorial_results/imputation/transformer/20230425_T093942, the tensorboard file will be saved to tutorial_results/imputation/transformer/20230425_T093942/tensorboard\n",
      "2023-04-25 09:39:42 [INFO]: Model initialized successfully with the number of trainable parameters: 7938597\n"
     ]
    }
   ],
   "source": [
    "from pypots.imputation import Transformer\n",
    "\n",
    "# initialize the model\n",
    "transformer = Transformer(\n",
    "    n_steps=physionet2012_dataset['n_steps'], \n",
    "    n_features=physionet2012_dataset['n_features'], \n",
    "    n_layers=6, \n",
    "    d_model=512, \n",
    "    d_inner=256, \n",
    "    n_head=8, \n",
    "    d_k=64, \n",
    "    d_v=64, \n",
    "    dropout=0.1, \n",
    "    epochs=10, # here we set epochs=10 for a quick demo, you can set it to 100 or more for better performance\n",
    "    patience=3, # here we set patience=5 to early stop the training if the evaluting loss doesn't decrease for 5 epoches. You can leave it to defualt as None to disable early stopping.\n",
    "    learning_rate=1e-3,\n",
    "    # device='cpu', # just leave it to default, PyPOTS will automatically assign the best device for you. \n",
    "                    # Set it to 'cpu' if you don't have CUDA devices. You can also set it to 'cuda:0' or 'cuda:1' if you have multiple CUDA devices.\n",
    "    saving_path=\"tutorial_results/imputation/transformer\", # set the path for saving tensorboard files\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 09:41:40 [INFO]: epoch 0: training loss 0.9016, validating loss 0.3464\n",
      "2023-04-25 09:43:38 [INFO]: epoch 1: training loss 0.5438, validating loss 0.3159\n",
      "2023-04-25 09:45:36 [INFO]: epoch 2: training loss 0.4648, validating loss 0.2850\n",
      "2023-04-25 09:47:38 [INFO]: epoch 3: training loss 0.4212, validating loss 0.2627\n",
      "2023-04-25 09:50:35 [INFO]: epoch 4: training loss 0.3916, validating loss 0.2648\n",
      "2023-04-25 09:53:16 [INFO]: epoch 5: training loss 0.3792, validating loss 0.2509\n",
      "2023-04-25 09:55:13 [INFO]: epoch 6: training loss 0.3636, validating loss 0.2464\n",
      "2023-04-25 09:57:14 [INFO]: epoch 7: training loss 0.3556, validating loss 0.2418\n",
      "2023-04-25 09:59:11 [INFO]: epoch 8: training loss 0.3492, validating loss 0.2416\n",
      "2023-04-25 10:01:06 [INFO]: epoch 9: training loss 0.3441, validating loss 0.2355\n",
      "2023-04-25 10:01:06 [INFO]: Finished training.\n",
      "2023-04-25 10:01:06 [INFO]: Saved successfully to tutorial_results/imputation/transformer/20230425_T093942/Transformer.pypots.\n"
     ]
    }
   ],
   "source": [
    "# train the model on the training set, and validate it on the validating set to select the best model for testing in the next step\n",
    "transformer.fit(train_set=dataset_for_training, val_set=dataset_for_validating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the testing stage, impute the originally-missing values and artificially-missing values in the test set\n",
    "transformer_imputation = transformer.impute(dataset_for_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing mean absolute error: 0.2352\n"
     ]
    }
   ],
   "source": [
    "from pypots.utils.metrics import cal_mae\n",
    "\n",
    "# calculate mean absolute error on the ground truth (artificially-missing values)\n",
    "testing_mae = cal_mae(transformer_imputation, physionet2012_dataset['test_X_intact'], physionet2012_dataset['test_X_indicating_mask'])\n",
    "print(\"Testing mean absolute error: %.4f\" % testing_mae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ An exmaple of **BRITS** for imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 10:01:17 [INFO]: No given device, using default device: cpu\n",
      "2023-04-25 10:01:17 [INFO]: saving_path is set as tutorial_results/imputation/brits, the trained model will be saved to tutorial_results/imputation/brits/20230425_T100117, the tensorboard file will be saved to tutorial_results/imputation/brits/20230425_T100117/tensorboard\n",
      "2023-04-25 10:01:17 [INFO]: Model initialized successfully with the number of trainable parameters: 239344\n"
     ]
    }
   ],
   "source": [
    "from pypots.imputation import BRITS\n",
    "\n",
    "# initialize the model\n",
    "brits = BRITS(\n",
    "    n_steps=physionet2012_dataset['n_steps'], \n",
    "    n_features=physionet2012_dataset['n_features'], \n",
    "    rnn_hidden_size=128, \n",
    "    epochs=10, # here we set epochs=10 for a quick demo, you can set it to 100 or more for better performance\n",
    "    patience=5, # here we set patience=5 to early stop the training if the evaluting loss doesn't decrease for 5 epoches. You can leave it to defualt as None to disable early stopping.\n",
    "    learning_rate=1e-3,\n",
    "    # device='cpu', # just leave it to default, PyPOTS will automatically assign the best device for you. \n",
    "                    # Set it to 'cpu' if you don't have CUDA devices. You can also set it to 'cuda:0' or 'cuda:1' if you have multiple CUDA devices.\n",
    "    saving_path=\"tutorial_results/imputation/brits\", # set the path for saving tensorboard files\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 10:02:25 [INFO]: epoch 0: training loss 0.9369, validating loss 0.3463\n",
      "2023-04-25 10:03:16 [INFO]: epoch 1: training loss 0.7322, validating loss 0.3044\n",
      "2023-04-25 10:04:06 [INFO]: epoch 2: training loss 0.6803, validating loss 0.2856\n",
      "2023-04-25 10:04:56 [INFO]: epoch 3: training loss 0.6554, validating loss 0.2778\n",
      "2023-04-25 10:05:46 [INFO]: epoch 4: training loss 0.6413, validating loss 0.2704\n",
      "2023-04-25 10:06:37 [INFO]: epoch 5: training loss 0.6301, validating loss 0.2670\n",
      "2023-04-25 10:07:27 [INFO]: epoch 6: training loss 0.6212, validating loss 0.2633\n",
      "2023-04-25 10:08:16 [INFO]: epoch 7: training loss 0.6145, validating loss 0.2613\n",
      "2023-04-25 10:09:06 [INFO]: epoch 8: training loss 0.6085, validating loss 0.2600\n",
      "2023-04-25 10:09:56 [INFO]: epoch 9: training loss 0.6033, validating loss 0.2575\n",
      "2023-04-25 10:09:56 [INFO]: Finished training.\n",
      "2023-04-25 10:09:56 [INFO]: Saved successfully to tutorial_results/imputation/brits/20230425_T100117/BRITS.pypots.\n"
     ]
    }
   ],
   "source": [
    "# train the model on the training set, and validate it on the validating set to select the best model for testing in the next step\n",
    "brits.fit(train_set=dataset_for_training, val_set=dataset_for_validating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the testing stage, impute the originally-missing values and artificially-missing values in the test set\n",
    "brits_imputation = brits.impute(dataset_for_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing mean absolute error: 0.2594\n"
     ]
    }
   ],
   "source": [
    "from pypots.utils.metrics import cal_mae\n",
    "\n",
    "# calculate mean absolute error on the ground truth (artificially-missing values)\n",
    "testing_mae = cal_mae(brits_imputation, physionet2012_dataset['test_X_intact'], physionet2012_dataset['test_X_indicating_mask'])\n",
    "print(\"Testing mean absolute error: %.4f\" % testing_mae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ An exmaple of **LOCF** for imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypots.imputation import LOCF\n",
    "\n",
    "# initialize the model\n",
    "locf = LOCF(\n",
    "    nan=0 # set the value used to impute data missing at the beginning of the sequence, those cannot use LOCF mechanism to impute\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pypots-dev/lib/python3.10/site-packages/pypots/imputation/locf.py:60: UserWarning: LOCF (Last Observed Carried Forward) imputation class has no parameter to train. Please run func impute(X) directly.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LOCF doesn't need to be trained, just call the impute() function\n",
    "\n",
    "locf.fit(train_set=dataset_for_training, val_set=dataset_for_validating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the testing stage, impute the originally-missing values and artificially-missing values in the test set\n",
    "locf_imputation = locf.impute(dataset_for_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing mean absolute error: 0.4122\n"
     ]
    }
   ],
   "source": [
    "from pypots.utils.metrics import cal_mae\n",
    "\n",
    "# calculate mean absolute error on the ground truth (artificially-missing values)\n",
    "testing_mae = cal_mae(locf_imputation, physionet2012_dataset['test_X_intact'], physionet2012_dataset['test_X_indicating_mask'])\n",
    "print(\"Testing mean absolute error: %.4f\" % testing_mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pypots-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
