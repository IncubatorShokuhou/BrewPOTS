{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“‘ Tutorials for PyPOTS Forecasting Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“€ Preparing the **PhysioNet-2012** dataset for this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 08:40:32 [INFO]: Loading the dataset physionet_2012 with TSDB (https://github.com/WenjieDu/Time_Series_Database)...\n",
      "2023-05-16 08:40:32 [INFO]: Starting preprocessing physionet_2012...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset physionet_2012 has already been downloaded. Processing directly...\n",
      "Dataset physionet_2012 has already been cached. Loading from cache directly...\n",
      "Loaded successfully!\n",
      "dict_keys(['n_classes', 'n_steps', 'n_features', 'train_X', 'train_y', 'val_X', 'val_y', 'test_X', 'test_y', 'scaler', 'test_X_intact', 'test_X_indicating_mask', 'val_X_intact', 'val_X_indicating_mask'])\n"
     ]
    }
   ],
   "source": [
    "from pypots.data.generating import gene_physionet2012\n",
    "\n",
    "# Load the PhysioNet-2012 dataset\n",
    "physionet2012_dataset = gene_physionet2012()\n",
    "\n",
    "# Take a look at the generated PhysioNet-2012 dataset, you'll find that everything has been prepared for you,\n",
    "# data splitting, normalization, additional artificially-missing values for evaluation, etc.\n",
    "print(physionet2012_dataset.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the datasets for training, validating, and testing.\n",
    "\n",
    "dataset_for_training = {\n",
    "    \"X\": physionet2012_dataset['train_X'],\n",
    "}\n",
    "\n",
    "dataset_for_validating = {\n",
    "    \"X\": physionet2012_dataset['val_X'],\n",
    "    \"X_intact\": physionet2012_dataset['val_X_intact'],\n",
    "    \"indicating_mask\": physionet2012_dataset['val_X_indicating_mask'],\n",
    "}\n",
    "\n",
    "dataset_for_testing = {\n",
    "    \"X\": physionet2012_dataset['test_X'][:, :36],  # we only take the first 36 steps for model input,\n",
    "    # and let the model to forecast the left 12 steps\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ An exmaple of **BTTF** for forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 08:41:02 [INFO]: No given device, using default device: cpu\n"
     ]
    }
   ],
   "source": [
    "from pypots.forecasting import BTTF\n",
    "import numpy as np\n",
    "# initialize the model\n",
    "bttf = BTTF(\n",
    "    36,\n",
    "    physionet2012_dataset[\"n_features\"],\n",
    "    pred_step=12,  # forcast the left half\n",
    "    rank=10,\n",
    "    time_lags=[1, 2, 3, 10, 10 + 1, 10 + 2, 20, 20 + 1, 20 + 2],\n",
    "    burn_iter=5,\n",
    "    gibbs_iter=5,\n",
    "    multi_step=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/PyPOTS/pypots/forecasting/bttf/model.py:334: UserWarning: Please run func forecast(X) directly.\n",
      "  warnings.warn(\"Please run func forecast(X) directly.\")\n"
     ]
    }
   ],
   "source": [
    "# train the model on the training set, and validate it on the validating set to select the best model for testing in the next step\n",
    "bttf.fit(train_set=dataset_for_training, val_set=dataset_for_validating)\n",
    "# BTTF does not need to run func fits().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the testing stage, impute the originally-missing values and artificially-missing values in the test set\n",
    "bttf_forecasting_results = bttf.forecast(dataset_for_testing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing mean absolute error: 0.8869\n"
     ]
    }
   ],
   "source": [
    "from pypots.utils.metrics import cal_mae\n",
    "\n",
    "# calculate mean absolute error on the ground truth (artificially-missing values)\n",
    "testing_mae = cal_mae(\n",
    "    bttf_forecasting_results,\n",
    "    np.nan_to_num(physionet2012_dataset['test_X'][:, 36:]),\n",
    "    (~np.isnan(physionet2012_dataset['test_X'][:, 36:])).astype(int),\n",
    ")\n",
    "print(\"Testing mean absolute error: %.4f\" % testing_mae)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pypots-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
